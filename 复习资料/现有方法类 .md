



## 0 SEQ类



就是顺序微调，没什么特别的



## 1 EWC类

弹性权重整合（Elastic Weight Consolidation, EWC）

其核心思想是通过正则化手段，限制对旧任务重要参数的修改。

正则化强度由超参数λ控制，而每个参数的重要性则由Fisher信息矩阵的对角线元素（即参数的“显著性”）决定。

正则化其实是你在最开始学习的时候用到的方法，正则化（Regularization）在深度学习中是一类用于防止模型过拟合（Overfitting）的技术，通过向损失函数添加约束或噪声，迫使模型在训练时保持简单性，从而提高泛化能力。

具体看  ./知识/正则化复习.md

Fisher信息矩阵是统计学中衡量“观测数据对模型参数的敏感度”的工具。在深度学习和持续学习（如EWC）中，它被用来评估“每个参数对任务的重要性”，即：

- 如果某个参数的微小变化会显著影响模型的输出（如预测概率或损失值），则该参数对任务很重要。
- 反之，如果参数的变化对模型影响很小，则它相对不重要。

具体看  ./知识/fisher矩阵.md    调整整个集合中的正则化损失权重 λ

## 2 REPLAY类

经验重放需要存储先前任务的代表性样本，并在学习新任务期间共同优化新旧样本。这种实用技术广泛用于持续学习。用于学习新任务的每个批次都包含来自重放缓冲区的一半新数据和一半旧数据，这比从组合数据集中随机采样产生更好的结果。



比如DER++

和基于DER++的CLSER

和LAMOL 生成重放   ——使用问答和生成目标来训练 LLM，在学习每个新任务之前生成伪样本，以实现有效的数据重放。我们探索了 λ ∈ {0.05， 0.10， 0.15， 0.20， 0.25， 0.30} 范围内的损失权重，而伪样本的比例固定为 γ = 0.20。LAMOL t 和 LAMOL g 这两个变体在生成过程中对任务特定标记的使用不同，对最终结果的影响可以忽略不计（差异小于 1%）。



## 3 微调类

PEFT类 adapter类 Prompt tuning类等等方式



## 4 基于模型混合的

Task Vector类

该方法通过“参数回滚”策略，在微调新任务后主动抵消部分参数更新，从而缓解灾难性遗忘。其核心是通过任务向量量化新任务的方向，并利用缩放系数 $\alpha$ 和终点epoch的选择，在“适应新任务”和“保留旧任务”之间找到平衡点。

记录2个关键检查点，假设旧任务0，现在要学习新任务1

起点（Wtask vec start epoch W task vec start epoch）：新任务训练前的初始模型（旧任务0的最优参数）。

终点（Wtask vec end epoch W task vec end epoch）：从预定义的候选epoch（如2, 4, 6, 8）中选择。

任务向量Task Vector = 终点参数 - 起点参数  该向量表示模型参数从旧任务到新任务的更新方向。

对任意一个检查点 Wckpt*W*ckpt（通常选新任务训练后的模型），通过减去缩放后的任务向量，得到最终模型：

$W_{final}=W_{ckpt}−α⋅Task Vector$

缩放系数 α：在 {0.16, 0.18, ..., 1.00} 范围内搜索最优值。

## 5 Gradient Projection

为了解决任务 0 对齐的破坏问题，

在初始训练阶段（如Task 0的150步训练），记录模型参数的更新方向（即梯度方向）。这个方向代表了任务A学习所需的参数空间变化。

在后续训练（如任务B）时，将所有梯度投影到第一步记录的梯度方向的**零空间**（Null Space）。数学上，零空间中的向量与原方向正交，因此投影后的梯度不会改变原任务的关键参数。

- 投影注意力层的梯度效果最好（Task 0准确率13.34%），但仍不理想。
- 投影所有层的梯度效果最差（9.52%），说明过度约束会损害模型的学习能力。



